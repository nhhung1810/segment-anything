{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from segment_anything.build_sam import sam_model_registry\n",
    "from scripts.experiments.mask_aug.inference import class_inference, load_model\n",
    "# from scripts.sam_train import SamTrain\n",
    "# from segment_anything.modeling.sam import Sam\n",
    "from scripts.datasets.constant import IMAGE_TYPE\n",
    "from scripts.datasets.preprocess_raw import FLARE22_Preprocess\n",
    "\n",
    "TRAIN_ROOT = \"../dataset/FLARE22-version1/FLARE22_LabeledCase50\"\n",
    "TRAIN_IMAGE_PATH = os.path.join(TRAIN_ROOT, \"images/*.nii.gz\")\n",
    "TRAIN_MASK_PATH = os.path.join(TRAIN_ROOT, \"labels/*.nii.gz\")\n",
    "\n",
    "VAL_ROOT = \"../dataset/FLARE22-version1/ReleaseValGT-20cases\"\n",
    "VAL_IMAGE_PATH = os.path.join(VAL_ROOT, \"images/*.nii.gz\")\n",
    "VAL_MASK_PATH = os.path.join(VAL_ROOT, \"labels/*.nii.gz\")\n",
    "\n",
    "train_images = sorted(list(glob(TRAIN_IMAGE_PATH)))\n",
    "train_masks = sorted(list(glob(TRAIN_MASK_PATH)))\n",
    "train_file = list(zip(train_images, train_masks))\n",
    "\n",
    "val_images = sorted(list(glob(VAL_IMAGE_PATH)))\n",
    "val_masks = sorted(list(glob(VAL_MASK_PATH)))\n",
    "val_file = list(zip(val_images, val_masks))\n",
    "\n",
    "# MODEL_PATH = \"../runs/transfer/imp-230603-150046/model-20.pt\"\n",
    "# MODEL_PATH = \"../runs/exps-230701-165310/model-20.pt\"\n",
    "\n",
    "# model: Sam = sam_model_registry[\"vit_b\"](\n",
    "#         checkpoint=\"../sam_vit_b_01ec64.pth\", custom=MODEL_PATH\n",
    "#     )\n",
    "# sam_train = SamTrain(sam_model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scripts.datasets.constant import FLARE22_LABEL_ENUM\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "preprocessor = FLARE22_Preprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.experiments.ssm.dataset import MeanShapeDataset\n",
    "MeanShapeDataset.TRAIN_CACHE_NAME = \"../mean-shape/train/\"\n",
    "MeanShapeDataset.VAL_CACHE_NAME = \"../mean-shape/validation/\"\n",
    "dataset = MeanShapeDataset(is_train_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.88\n"
     ]
    }
   ],
   "source": [
    "print(dataset.mean_z)\n",
    "volumes, masks = preprocessor.run_with_config(\n",
    "    image_file=train_file[0][0],\n",
    "    gt_file=train_file[0][1],\n",
    "    config_name=IMAGE_TYPE.ABDOMEN_SOFT_TISSUES_ABDOMEN_LIVER,\n",
    ")\n",
    "volumes = volumes[::-1]\n",
    "masks = masks[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 0.002, 0.300, 0.042, 0.045\n"
     ]
    }
   ],
   "source": [
    "from scripts.experiments.ssm.model import SimpleSDFModel\n",
    "\n",
    "model = SimpleSDFModel(n_input=3, n_output=1, n_hidden=10)\n",
    "model.load_state_dict(torch.load(\"../runs/stat-shape-230706-005124/model-8.pt\"))\n",
    "with torch.no_grad():\n",
    "    coords = np.argwhere(np.ones(volumes.shape))\n",
    "    normalized_coords = coords / np.array([[dataset.mean_z, 512, 512]])\n",
    "    pred = model(torch.Tensor(normalized_coords))\n",
    "    pred = pred.numpy()\n",
    "    mi, ma, me, st = np.min(pred), np.max(pred), np.mean(pred), np.std(pred)\n",
    "    print(f\"Statistic: {mi:.3f}, {ma:.3f}, {me:.3f}, {st:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_arr = np.pad(coords, pad_width=((0, 0), (0, 1)), constant_values=0.0)\n",
    "merge_arr[:, 3:] = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_arr[:, 3] == True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fbrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
