{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from segment_anything.build_sam import sam_model_registry\n",
    "from scripts.experiments.mask_aug.inference import class_inference, load_model\n",
    "from scripts.sam_train import SamTrain\n",
    "from segment_anything.modeling.sam import Sam\n",
    "VAL_ROOT = \"../dataset/FLARE22-version1/ReleaseValGT-20cases\"\n",
    "VOLUME_CACHE = os.path.join(VAL_ROOT, \"images/FLARETs_0002_0000.cache.pt\")\n",
    "IMAGE_PATH = os.path.join(VAL_ROOT, \"images/FLARETs_0002_0000.nii.gz\")\n",
    "MASK_PATH = os.path.join(VAL_ROOT, \"labels/FLARETs_0002.nii.gz\")\n",
    "# MODEL_PATH = \"../runs/transfer/imp-230603-150046/model-20.pt\"\n",
    "MODEL_PATH = \"../runs/exps-230701-165310/model-20.pt\"\n",
    "\n",
    "model: Sam = sam_model_registry[\"vit_b\"](\n",
    "        checkpoint=\"../sam_vit_b_01ec64.pth\", custom=MODEL_PATH\n",
    "    )\n",
    "sam_train = SamTrain(sam_model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scripts.datasets.constant import IMAGE_TYPE\n",
    "from scripts.datasets.preprocess_raw import FLARE22_Preprocess\n",
    "from scripts.utils import torch_try_load\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "preprocessor = FLARE22_Preprocess()\n",
    "volumes, masks = preprocessor.run_with_config(\n",
    "            image_file=IMAGE_PATH,\n",
    "            gt_file=MASK_PATH,\n",
    "            config_name=IMAGE_TYPE.ABDOMEN_SOFT_TISSUES_ABDOMEN_LIVER,\n",
    "        )\n",
    "cache_volume = torch_try_load(VOLUME_CACHE, 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.experiments.mask_aug.inference import get_all_organ_range\n",
    "\n",
    "\n",
    "starts, ends = get_all_organ_range(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0, 102,  85, 123, 104,  81,  79, 130, 118, 126, 151, 114,  97,\n",
       "         93]),\n",
       " array([  0, 161, 140, 149, 148, 170, 162, 145, 132, 132, 170, 154, 131,\n",
       "        123]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts, ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time_ns\n",
    "from typing import Dict\n",
    "\n",
    "from scripts.datasets.f22_improve import Augmentation\n",
    "from scripts.experiments.mask_aug.inference import pick_best_mask\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "aug_fn = Augmentation({})\n",
    "\n",
    "def pick_one_pixel(mask: torch.Tensor, radius=3, seed=10, gaussian_config=None):\n",
    "    # binary mask input\n",
    "    coors = torch.argwhere(mask)\n",
    "    idx = np.random.RandomState(seed=seed).randint(low=0, high=coors.shape[0])\n",
    "    x = coors[idx][0].item()\n",
    "    y = coors[idx][1].item()\n",
    "    result = np.zeros(mask.shape)\n",
    "    xmax = min(x + radius, mask.shape[0])\n",
    "    ymax = min(y + radius, mask.shape[1])\n",
    "    xmin = max(x - radius, 0)\n",
    "    ymin = max(y - radius, 0)\n",
    "    result[xmin:xmax, ymin:ymax] = 1.0\n",
    "\n",
    "    if gaussian_config:\n",
    "        result = gaussian_filter(result, sigma=gaussian_config['sigma'])\n",
    "        result = (result - np.min(result)) / (np.max(result) - np.min(result))\n",
    "    \n",
    "    result = torch.as_tensor(result)\n",
    "    return result\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(\n",
    "        volumes: np.ndarray, \n",
    "        masks: np.ndarray, \n",
    "        caches: np.ndarray, \n",
    "        idx: int, \n",
    "        target_idx: int,\n",
    "        radius:int,\n",
    "        seed:int,\n",
    "        gaussian_config:Dict[str, object]=None,\n",
    "    ):\n",
    "    original_size = caches[idx]['original_size']\n",
    "    input_size = caches[idx]['input_size']\n",
    "    img_emb = caches[idx]['img_emb']\n",
    "    \n",
    "    previous_mask = torch.as_tensor(masks[idx - 1].copy() == target_idx)\n",
    "    # previous_mask = aug_fn.one_block_drop(previous_mask, max_crop_ratio=0.9, augmentation_prop=1.0)\n",
    "    previous_mask = pick_one_pixel(previous_mask, radius=radius, seed=seed, gaussian_config=gaussian_config)\n",
    "    \n",
    "    start = time_ns()\n",
    "    _, _, _, mask_input_torch = sam_train.prepare_prompt(\n",
    "        original_size=original_size, mask_input=previous_mask[None, ...]\n",
    "    )\n",
    "\n",
    "    mask_logits, _, low_res_mask = sam_train.predict_torch(\n",
    "        image_emb=img_emb,  # 1, 256, 64, 64\n",
    "        input_size=input_size,\n",
    "        original_size=original_size,\n",
    "        multimask_output=True,\n",
    "        # Get the logit to compute the stability\n",
    "        return_logits=True,\n",
    "        mask_input=mask_input_torch,\n",
    "    )\n",
    "\n",
    "    mask_pred = mask_logits > 0.0\n",
    "    \n",
    "    chosen_idx, _ = pick_best_mask(\n",
    "        pred_multi_mask=mask_pred,\n",
    "        previous_mask=previous_mask,\n",
    "        gt_binary_mask=None,\n",
    "        device='cpu',\n",
    "        strategy='prev'\n",
    "    )\n",
    "    stop = time_ns()\n",
    "    duration = stop - start\n",
    "    return chosen_idx, mask_pred, low_res_mask, mask_logits, duration, previous_mask\n",
    "\n",
    "\n",
    "chosen_idx, mask_pred, low_res_mask, mask_logits, duration, previous_mask = inference(\n",
    "    volumes=volumes,\n",
    "    masks=masks,\n",
    "    caches=cache_volume,\n",
    "    idx=120,\n",
    "    target_idx=1,\n",
    "    radius=20,\n",
    "    seed=10,\n",
    "    gaussian_config=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pick_square() got an unexpected keyword argument 'radius'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m130\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m aug_fn\u001b[39m.\u001b[39;49mpick_square(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     mask\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mas_tensor((masks[idx] \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49muint8), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49muint8)\u001b[39m.\u001b[39;49mclone(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     radius\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# f, ax = plt.subplots(1, 2)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# ax[0].imshow(result.numpy())\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# ax[1].imshow(masks[130] == 1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hung.nh/codespace/yauangon/thesis/segment-anything/notebooks/expansion.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(result\u001b[39m.\u001b[39mnumpy()\u001b[39m*\u001b[39m\u001b[39m10\u001b[39m \u001b[39m+\u001b[39m masks[idx])\n",
      "\u001b[0;31mTypeError\u001b[0m: pick_square() got an unexpected keyword argument 'radius'"
     ]
    }
   ],
   "source": [
    "idx = 130\n",
    "result = aug_fn.pick_square(\n",
    "    mask=torch.as_tensor((masks[idx] == 1).astype(np.uint8), dtype=torch.uint8).clone(),\n",
    "    radius=5\n",
    ")\n",
    "# f, ax = plt.subplots(1, 2)\n",
    "# ax[0].imshow(result.numpy())\n",
    "# ax[1].imshow(masks[130] == 1)\n",
    "plt.imshow(result.numpy()*10 + masks[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "idx = 134\n",
    "previous_mask = masks[idx - 1].copy() == 1\n",
    "target_mask = masks[idx].copy() == 1\n",
    "img = volumes[idx]\n",
    "\n",
    "chosen_idx, mask_pred, low_res_mask, mask_logits, duration, previous_mask = inference(\n",
    "    volumes=volumes,\n",
    "    masks=masks,\n",
    "    caches=cache_volume,\n",
    "    idx=idx,\n",
    "    target_idx=1,\n",
    "    radius=10,\n",
    "    seed=(time_ns() & (2**32 - 1)),\n",
    "    gaussian_config={'sigma': 30}\n",
    ")\n",
    "\n",
    "f, axes = plt.subplots(2, 3)\n",
    "axes[0, 0].imshow(mask_pred[0, chosen_idx])\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[0, 2].imshow(low_res_mask[0, chosen_idx].numpy())\n",
    "\n",
    "axes[1, 0].imshow(previous_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "axes[1, 2].imshow(mask_logits[0, chosen_idx].numpy())\n",
    "\n",
    "axes[0, 0].set_title('Pred')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Previous')\n",
    "axes[1, 1].set_title('Image')\n",
    "# plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.utils.amg import calculate_stability_score\n",
    "r = []\n",
    "for value in range(-20, 20, 1):\n",
    "    result = calculate_stability_score(masks=mask_logits[0, chosen_idx], mask_threshold=value / 2.0, threshold_offset=1.0)\n",
    "    r.append((value / 2.0, result))\n",
    "\n",
    "print(r)\n",
    "print(max(r, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 3)\n",
    "axes[0, 0].imshow(mask_logits[0, chosen_idx].numpy() > -10.)\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[0, 2].imshow(low_res_mask[0, chosen_idx].numpy())\n",
    "\n",
    "axes[1, 0].imshow(previous_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "axes[1, 2].imshow(mask_logits[0, chosen_idx].numpy() - 0.5)\n",
    "\n",
    "axes[0, 0].set_title('Pred')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Previous')\n",
    "axes[1, 1].set_title('Image')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_minmax(inp):\n",
    "    return (inp - np.min(inp)) / (np.max(inp) - np.min(inp))\n",
    "\n",
    "\n",
    "def evolution(\n",
    "        masks: np.ndarray, \n",
    "        caches: np.ndarray, \n",
    "        idx: int, \n",
    "        target_idx: int,\n",
    "        start_radius: int,\n",
    "        gaussian_config: Dict[str, object],\n",
    "        n_round: int,\n",
    "        seed: int,\n",
    "    ):\n",
    "    original_size = caches[idx]['original_size']\n",
    "    input_size = caches[idx]['input_size']\n",
    "    img_emb = caches[idx]['img_emb']\n",
    "\n",
    "    dices = []\n",
    "    result = []\n",
    "    \n",
    "    previous_mask = torch.as_tensor(masks[idx - 1].copy() == target_idx)\n",
    "    previous_mask = pick_one_pixel(previous_mask, radius=start_radius, gaussian_config=gaussian_config, seed=seed)\n",
    "    init_mask = previous_mask.clone()\n",
    "\n",
    "    for _ in range(n_round):\n",
    "        _, _, _, mask_input_torch = sam_train.prepare_prompt(\n",
    "            original_size=original_size, mask_input=previous_mask[None, ...]\n",
    "        )\n",
    "\n",
    "        mask_logits, _, _ = sam_train.predict_torch(\n",
    "            image_emb=img_emb,  # 1, 256, 64, 64\n",
    "            input_size=input_size,\n",
    "            original_size=original_size,\n",
    "            multimask_output=True,\n",
    "            # Get the logit to compute the stability\n",
    "            return_logits=True,\n",
    "            mask_input=mask_input_torch,\n",
    "        )\n",
    "\n",
    "        mask_pred = mask_logits > 0.0\n",
    "        \n",
    "        chosen_idx, dice_score = pick_best_mask(\n",
    "            pred_multi_mask=mask_pred,\n",
    "            previous_mask=previous_mask,\n",
    "            gt_binary_mask=None,\n",
    "            device='cpu',\n",
    "            strategy='prev'\n",
    "        )\n",
    "        dices.append(dice_score)\n",
    "        previous_mask = mask_pred[0, chosen_idx].numpy()\n",
    "        if gaussian_config is not None:\n",
    "            if gaussian_config.get('prev_sigma') is not None:\n",
    "                previous_mask = gaussian_filter(previous_mask.astype(np.float32), sigma=gaussian_config['prev_sigma'])\n",
    "                previous_mask = norm_minmax(previous_mask)\n",
    "        result.append(previous_mask.copy())\n",
    "        pass\n",
    "    \n",
    "    return chosen_idx, mask_pred, result, init_mask, dices\n",
    "\n",
    "idx = 131\n",
    "chosen_idx, mask_pred, result, init_mask, dices = evolution(\n",
    "    masks=masks,\n",
    "    caches=cache_volume,\n",
    "    idx=idx,\n",
    "    target_idx=1,\n",
    "    start_radius=4,\n",
    "    n_round=10,\n",
    "    gaussian_config={\n",
    "        'sigma': 10.0,\n",
    "        'prev_sigma': 3.5,\n",
    "    },\n",
    "    seed=(time_ns() & (2**32 - 1)),\n",
    "    # seed=10,\n",
    ")\n",
    "\n",
    "target_mask = masks[idx].copy() == 1\n",
    "img = volumes[idx]\n",
    "\n",
    "f, axes = plt.subplots(2, 2)\n",
    "axes[0, 0].imshow(mask_pred[0, chosen_idx])\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[1, 0].imshow(init_mask*10 + target_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "\n",
    "axes[0, 0].set_title('Pred')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Target with init overlay')\n",
    "axes[1, 1].set_title('Image')\n",
    "\n",
    "print(dices)\n",
    "\n",
    "f, axes = plt.subplots(3, 4)\n",
    "for i1 in range(3):\n",
    "    for i2 in range(4):\n",
    "        if i1 * 4 + i2 >= len(result): break\n",
    "        axes[i1, i2].imshow(result[i1 * 4 + i2])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "def expansion_metric(a1: Tensor, a2: Tensor):\n",
    "    if not isinstance(a1, Tensor):\n",
    "        a1 = Tensor(a1)\n",
    "    if not isinstance(a2, Tensor):\n",
    "        a2 = Tensor(a2)\n",
    "    intersection = (a1 * a2).sum()\n",
    "    # Check the intersection coverage compare to the max\n",
    "    expansion_ratio = torch.max(a1.sum(), a2.sum()) / intersection\n",
    "    coverage_ratio = intersection / torch.min(a1.sum(), a2.sum())\n",
    "    return expansion_ratio, coverage_ratio\n",
    "\n",
    "expansion_ratio, coverage_ratio = expansion_metric(result[0] > 0.0, result[-1] > 0.0)\n",
    "print(\n",
    "    expansion_ratio,\n",
    "    coverage_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkern(l=5, sig=1.):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length `l` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def create_gaussian_2d_kernel(length: int, sigma: float):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length `l` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = torch.linspace(-(length - 1) / 2.0, (length - 1) / 2.0, length)\n",
    "    gauss = torch.exp(-0.5 * torch.square(ax) / torch.square(torch.as_tensor(sigma)))\n",
    "    kernel = torch.outer(gauss, gauss)\n",
    "    return kernel / torch.sum(kernel)\n",
    "\n",
    "gkern() - create_gaussian_2d_kernel(5, 1.).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_score(logits, threshold):\n",
    "    # Idea: confidence is high when the prob of \n",
    "    # foreground high and prob of background is low\n",
    "    foreground_score = np.mean(logits[logits >= threshold])\n",
    "    background_score = 1.0 - np.mean(logits[logits < threshold])\n",
    "    return np.mean([foreground_score, background_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional\n",
    "import uuid\n",
    "\n",
    "class BeamSearchInferenceEngine:\n",
    "    def __init__(\n",
    "            self, \n",
    "            volumes: Tensor, \n",
    "            caches: Tensor, \n",
    "            masks: Tensor, \n",
    "            stability_config: Dict[str, object]\n",
    "            ) -> None:\n",
    "        self.volumes = volumes\n",
    "        self.caches = caches\n",
    "        self.masks = masks\n",
    "        \n",
    "        self.stability_config = self.prepare_default_stability_config(stability_config)\n",
    "        self.starts, self.ends = get_all_organ_range(masks)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "\n",
    "    def prepare_default_stability_config(self, stability_config: Dict[str, object]):\n",
    "        stability_config = stability_config or {}\n",
    "        stability_config['threshold_start'] = stability_config.get('threshold_start', 0.1)\n",
    "        stability_config['threshold_end'] = stability_config.get('threshold_end', 0.9)\n",
    "        stability_config['threshold_num'] = stability_config.get('threshold_num', 10)\n",
    "        stability_config['offset'] = stability_config.get('offset', 0.1)\n",
    "        return stability_config\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def core_inference(self, idx: int, previous_mask: Tensor):\n",
    "        original_size = self.caches[idx]['original_size']\n",
    "        input_size = self.caches[idx]['input_size']\n",
    "        img_emb = self.caches[idx]['img_emb']\n",
    "\n",
    "        _, _, _, mask_input_torch = sam_train.prepare_prompt(\n",
    "            original_size=original_size, mask_input=previous_mask[None, ...]\n",
    "            )\n",
    "\n",
    "        mask_logits, _, _ = sam_train.predict_torch(\n",
    "            image_emb=img_emb,  # 1, 256, 64, 64\n",
    "            input_size=input_size,\n",
    "            original_size=original_size,\n",
    "            multimask_output=True,\n",
    "            # Get the logits to compute the stability\n",
    "            return_logits=True,\n",
    "            mask_input=mask_input_torch,\n",
    "        )\n",
    "\n",
    "        mask_pred = mask_logits > 0.0\n",
    "        \n",
    "        chosen_idx, _ = pick_best_mask(\n",
    "            pred_multi_mask=mask_pred,\n",
    "            previous_mask=previous_mask,\n",
    "            gt_binary_mask=None,\n",
    "            device='cpu',\n",
    "            strategy='prev'\n",
    "        )\n",
    "        \n",
    "        return chosen_idx, mask_logits\n",
    "    \n",
    "    def calculate_stability_score_with_sigmoid(\n",
    "        self, masks: torch.Tensor, mask_threshold: float, threshold_offset: float\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Exactly like the `calculate_stability_score`, but using sigmoid for better scale\n",
    "        \"\"\"\n",
    "        # One mask is always contained inside the other.\n",
    "        # Save memory by preventing unnecessary cast to torch.int64\n",
    "        sigmoid_masks = torch.sigmoid(masks)\n",
    "        intersections = (\n",
    "            (sigmoid_masks > (mask_threshold + threshold_offset))\n",
    "            .sum(-1, dtype=torch.int16)\n",
    "            .sum(-1, dtype=torch.int32)\n",
    "        )\n",
    "        unions = (\n",
    "            (sigmoid_masks > (mask_threshold - threshold_offset))\n",
    "            .sum(-1, dtype=torch.int16)\n",
    "            .sum(-1, dtype=torch.int32)\n",
    "        )\n",
    "        return intersections / unions\n",
    "    \n",
    "    def generate_option(self, mask_logits, chosen_idx, prev_id):\n",
    "        options = []\n",
    "        start = self.stability_config['threshold_start']\n",
    "        end = self.stability_config['threshold_end']\n",
    "        num = self.stability_config['threshold_num']\n",
    "        for value in np.linspace(start=start, stop=end, num=num):\n",
    "            score = self.calculate_stability_score_with_sigmoid(\n",
    "                masks=mask_logits[0, chosen_idx],\n",
    "                mask_threshold=value, \n",
    "                threshold_offset=self.stability_config['offset']\n",
    "                )\n",
    "            options.append([value, score, uuid.uuid4(), prev_id, mask_logits[0, chosen_idx]])\n",
    "        return options\n",
    "\n",
    "    def ranking_fn(self, options, score):\n",
    "        for option in options:\n",
    "            score  = score + np.log(option[1] + 1e-30)\n",
    "            option[1] = score\n",
    "            pass\n",
    "        \n",
    "        return sorted(options, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    def beam_search_inference(\n",
    "            self, \n",
    "            start_idx: int, \n",
    "            end_idx: int,\n",
    "            target_idx: int, \n",
    "            start_radius: float, \n",
    "            gaussian_config: Dict[str, object], \n",
    "            seed: Optional[int] = None, \n",
    "            beam_width: int = 3,\n",
    "        ):\n",
    "        if seed is None:\n",
    "            seed = time_ns() % (2**32 - 1)\n",
    "        \n",
    "        init_mask = torch.as_tensor(self.masks[start_idx - 1].copy() == target_idx)\n",
    "        init_mask = pick_one_pixel(init_mask, radius=start_radius, gaussian_config=gaussian_config, seed=seed)\n",
    "        score = 0.0\n",
    "        options = [[0.0, 1.0, uuid.uuid4(), None, init_mask]]\n",
    "        tracing = []\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            buffer = []\n",
    "            for option in options:\n",
    "                previous_mask = option[-1] > option[0] if option[-2] is not None else option[-1]\n",
    "                chosen_idx, mask_logits = self.core_inference(\n",
    "                    idx=idx, previous_mask=previous_mask\n",
    "                )\n",
    "                new_options = self.generate_option(mask_logits, chosen_idx, prev_id=option[2])\n",
    "                buffer.extend(new_options)\n",
    "                pass\n",
    "            options = self.ranking_fn(buffer, score)[:beam_width]\n",
    "            tracing.append(options)\n",
    "            pass\n",
    "        \n",
    "        return tracing, init_mask\n",
    "    \n",
    "    def retrace(self, tracing: List[object]):\n",
    "        result = []\n",
    "        best_option = max(tracing[-1], key=lambda x: x[1])\n",
    "        [value, score, current_id, prev_id, mask_logits] = best_option\n",
    "        pred = mask_logits > value\n",
    "        result.append(pred)\n",
    "        # reverse, skip the last option\n",
    "        for trace in tracing[-2::-1]:\n",
    "            best_option = next(filter(lambda x: x[2] == prev_id, trace))\n",
    "            [value, _, current_id, prev_id, mask_logits] = best_option\n",
    "            pred = mask_logits > value\n",
    "            result.append(pred)\n",
    "            pass\n",
    "        # reverse the tracing again\n",
    "        return result[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = BeamSearchInferenceEngine(volumes=volumes, caches=cache_volume, masks=masks, stability_config=None)\n",
    "tracing, init_mask = engine.beam_search_inference(\n",
    "    start_idx=130,\n",
    "    end_idx=140,\n",
    "    target_idx=1,\n",
    "    start_radius=3,\n",
    "    gaussian_config={'sigma': 10.0},\n",
    "    beam_width=3,\n",
    "    # seed=1810\n",
    ")\n",
    "data = engine.retrace(tracing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 139\n",
    "target_mask = masks[idx].copy() == 1\n",
    "img = volumes[idx]\n",
    "f, axes = plt.subplots(2, 2)\n",
    "axes[0, 0].imshow(data[idx - 130])\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[1, 0].imshow(init_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "\n",
    "axes[0, 0].set_title('Pred')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Init mask')\n",
    "axes[1, 1].set_title('Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Augmentation(aug_config=None, seed=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fbrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
