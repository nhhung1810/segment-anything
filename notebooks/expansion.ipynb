{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from segment_anything.build_sam import sam_model_registry\n",
    "from scripts.experiments.mask_aug.inference import class_inference, load_model\n",
    "from scripts.sam_train import SamTrain\n",
    "from segment_anything.modeling.sam import Sam\n",
    "VAL_ROOT = \"../dataset/FLARE22-version1/ReleaseValGT-20cases\"\n",
    "VOLUME_CACHE = os.path.join(VAL_ROOT, \"images/FLARETs_0002_0000.cache.pt\")\n",
    "IMAGE_PATH = os.path.join(VAL_ROOT, \"images/FLARETs_0002_0000.nii.gz\")\n",
    "MASK_PATH = os.path.join(VAL_ROOT, \"labels/FLARETs_0002.nii.gz\")\n",
    "MODEL_PATH = \"../runs/transfer/imp-230603-150046/model-20.pt\"\n",
    "# MODEL_PATH = \"../runs/exps-230701-165310/model-20.pt\"\n",
    "\n",
    "model: Sam = sam_model_registry[\"vit_b\"](\n",
    "        checkpoint=\"../sam_vit_b_01ec64.pth\", custom=MODEL_PATH\n",
    "    )\n",
    "sam_train = SamTrain(sam_model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scripts.datasets.constant import IMAGE_TYPE\n",
    "from scripts.datasets.preprocess_raw import FLARE22_Preprocess\n",
    "from scripts.utils import torch_try_load\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "preprocessor = FLARE22_Preprocess()\n",
    "volumes, masks = preprocessor.run_with_config(\n",
    "            image_file=IMAGE_PATH,\n",
    "            gt_file=MASK_PATH,\n",
    "            config_name=IMAGE_TYPE.ABDOMEN_SOFT_TISSUES_ABDOMEN_LIVER,\n",
    "        )\n",
    "cache_volume = torch_try_load(VOLUME_CACHE, 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.experiments.mask_aug.inference import get_all_organ_range\n",
    "\n",
    "\n",
    "starts, ends = get_all_organ_range(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts, ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time_ns\n",
    "from typing import Dict\n",
    "\n",
    "from scripts.datasets.f22_improve import Augmentation\n",
    "from scripts.experiments.mask_aug.inference import pick_best_mask\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "aug_fn = Augmentation({})\n",
    "\n",
    "def pick_one_pixel(mask: torch.Tensor, radius=3, seed=10, gaussian_config=None):\n",
    "    # binary mask input\n",
    "    coors = torch.argwhere(mask)\n",
    "    idx = np.random.RandomState(seed=seed).randint(low=0, high=coors.shape[0])\n",
    "    x = coors[idx][0].item()\n",
    "    y = coors[idx][1].item()\n",
    "    result = np.zeros(mask.shape)\n",
    "    xmax = min(x + radius, mask.shape[0])\n",
    "    ymax = min(y + radius, mask.shape[1])\n",
    "    xmin = max(x - radius, 0)\n",
    "    ymin = max(y - radius, 0)\n",
    "    result[xmin:xmax, ymin:ymax] = 1.0\n",
    "\n",
    "    if gaussian_config:\n",
    "        result = gaussian_filter(result, sigma=gaussian_config['sigma'])\n",
    "        result = (result - np.min(result)) / (np.max(result) - np.min(result))\n",
    "    \n",
    "    result = torch.as_tensor(result)\n",
    "    return result\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(\n",
    "        volumes: np.ndarray, \n",
    "        masks: np.ndarray, \n",
    "        caches: np.ndarray, \n",
    "        idx: int, \n",
    "        target_idx: int,\n",
    "        radius:int,\n",
    "        seed:int,\n",
    "        gaussian_config:Dict[str, object]=None,\n",
    "    ):\n",
    "    original_size = caches[idx]['original_size']\n",
    "    input_size = caches[idx]['input_size']\n",
    "    img_emb = caches[idx]['img_emb']\n",
    "    \n",
    "    previous_mask = torch.as_tensor(masks[idx - 1].copy() == target_idx)\n",
    "    # previous_mask = aug_fn.one_block_drop(previous_mask, max_crop_ratio=0.9, augmentation_prop=1.0)\n",
    "    previous_mask = pick_one_pixel(previous_mask, radius=radius, seed=seed, gaussian_config=gaussian_config)\n",
    "    \n",
    "    start = time_ns()\n",
    "    _, _, _, mask_input_torch = sam_train.prepare_prompt(\n",
    "        original_size=original_size, mask_input=previous_mask[None, ...]\n",
    "    )\n",
    "\n",
    "    mask_logits, _, low_res_mask = sam_train.predict_torch(\n",
    "        image_emb=img_emb,  # 1, 256, 64, 64\n",
    "        input_size=input_size,\n",
    "        original_size=original_size,\n",
    "        multimask_output=True,\n",
    "        # Get the logit to compute the stability\n",
    "        return_logits=True,\n",
    "        mask_input=mask_input_torch,\n",
    "    )\n",
    "\n",
    "    mask_pred = mask_logits > 0.0\n",
    "    \n",
    "    chosen_idx, _ = pick_best_mask(\n",
    "        pred_multi_mask=mask_pred,\n",
    "        previous_mask=previous_mask,\n",
    "        gt_binary_mask=None,\n",
    "        device='cpu',\n",
    "        strategy='prev'\n",
    "    )\n",
    "    stop = time_ns()\n",
    "    duration = stop - start\n",
    "    return chosen_idx, mask_pred, low_res_mask, mask_logits, duration, previous_mask\n",
    "\n",
    "\n",
    "chosen_idx, mask_pred, low_res_mask, mask_logits, duration, previous_mask = inference(\n",
    "    volumes=volumes,\n",
    "    masks=masks,\n",
    "    caches=cache_volume,\n",
    "    idx=120,\n",
    "    target_idx=1,\n",
    "    radius=20,\n",
    "    seed=10,\n",
    "    gaussian_config=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 130\n",
    "result = aug_fn.pick_square(\n",
    "    mask=torch.as_tensor((masks[idx] == 1).astype(np.uint8), dtype=torch.uint8).clone(),\n",
    "    radius_width=5,\n",
    ")\n",
    "# f, ax = plt.subplots(1, 2)\n",
    "# ax[0].imshow(result.numpy())\n",
    "# ax[1].imshow(masks[130] == 1)\n",
    "plt.imshow(result.numpy()*10 + masks[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "idx = 134\n",
    "previous_mask = masks[idx - 1].copy() == 1\n",
    "target_mask = masks[idx].copy() == 1\n",
    "img = volumes[idx]\n",
    "\n",
    "chosen_idx, mask_pred, low_res_mask, mask_logits, duration, previous_mask = inference(\n",
    "    volumes=volumes,\n",
    "    masks=masks,\n",
    "    caches=cache_volume,\n",
    "    idx=idx,\n",
    "    target_idx=1,\n",
    "    radius=10,\n",
    "    seed=(time_ns() & (2**32 - 1)),\n",
    "    gaussian_config={'sigma': 30}\n",
    ")\n",
    "\n",
    "f, axes = plt.subplots(2, 3)\n",
    "axes[0, 0].imshow(mask_pred[0, chosen_idx])\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[0, 2].imshow(low_res_mask[0, chosen_idx].numpy())\n",
    "\n",
    "axes[1, 0].imshow(previous_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "axes[1, 2].imshow(mask_logits[0, chosen_idx].numpy())\n",
    "\n",
    "axes[0, 0].set_title('Pred')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Previous')\n",
    "axes[1, 1].set_title('Image')\n",
    "# plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.utils.amg import calculate_stability_score\n",
    "r = []\n",
    "for value in range(-20, 20, 1):\n",
    "    result = calculate_stability_score(masks=mask_logits[0, chosen_idx], mask_threshold=value / 2.0, threshold_offset=1.0)\n",
    "    r.append((value / 2.0, result))\n",
    "\n",
    "print(r)\n",
    "print(max(r, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 3)\n",
    "axes[0, 0].imshow(mask_logits[0, chosen_idx].numpy() > -10.)\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[0, 2].imshow(low_res_mask[0, chosen_idx].numpy())\n",
    "\n",
    "axes[1, 0].imshow(previous_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "axes[1, 2].imshow(mask_logits[0, chosen_idx].numpy() - 0.5)\n",
    "\n",
    "axes[0, 0].set_title('Pred')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Previous')\n",
    "axes[1, 1].set_title('Image')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_minmax(inp):\n",
    "    return (inp - np.min(inp)) / (np.max(inp) - np.min(inp))\n",
    "\n",
    "\n",
    "def evolution(\n",
    "        masks: np.ndarray, \n",
    "        caches: np.ndarray, \n",
    "        idx: int, \n",
    "        target_idx: int,\n",
    "        start_radius: int,\n",
    "        gaussian_config: Dict[str, object],\n",
    "        n_round: int,\n",
    "        seed: int,\n",
    "    ):\n",
    "    original_size = caches[idx]['original_size']\n",
    "    input_size = caches[idx]['input_size']\n",
    "    img_emb = caches[idx]['img_emb']\n",
    "\n",
    "    dices = []\n",
    "    result = []\n",
    "    \n",
    "    previous_mask = torch.as_tensor(masks[idx - 1].copy() == target_idx)\n",
    "    previous_mask = pick_one_pixel(previous_mask, radius=start_radius, gaussian_config=gaussian_config, seed=seed)\n",
    "    init_mask = previous_mask.clone()\n",
    "\n",
    "    for _ in range(n_round):\n",
    "        _, _, _, mask_input_torch = sam_train.prepare_prompt(\n",
    "            original_size=original_size, mask_input=previous_mask[None, ...]\n",
    "        )\n",
    "\n",
    "        mask_logits, _, _ = sam_train.predict_torch(\n",
    "            image_emb=img_emb,  # 1, 256, 64, 64\n",
    "            input_size=input_size,\n",
    "            original_size=original_size,\n",
    "            multimask_output=True,\n",
    "            # Get the logit to compute the stability\n",
    "            return_logits=True,\n",
    "            mask_input=mask_input_torch,\n",
    "        )\n",
    "\n",
    "        mask_pred = mask_logits > 0.0\n",
    "        \n",
    "        chosen_idx, dice_score = pick_best_mask(\n",
    "            pred_multi_mask=mask_pred,\n",
    "            previous_mask=previous_mask,\n",
    "            gt_binary_mask=None,\n",
    "            device='cpu',\n",
    "            strategy='prev'\n",
    "        )\n",
    "        dices.append(dice_score)\n",
    "        previous_mask = mask_pred[0, chosen_idx].numpy()\n",
    "        if gaussian_config is not None:\n",
    "            if gaussian_config.get('prev_sigma') is not None:\n",
    "                previous_mask = gaussian_filter(previous_mask.astype(np.float32), sigma=gaussian_config['prev_sigma'])\n",
    "                previous_mask = norm_minmax(previous_mask)\n",
    "        result.append(previous_mask.copy())\n",
    "        pass\n",
    "    \n",
    "    return chosen_idx, mask_pred, result, init_mask, dices\n",
    "\n",
    "idx = 131\n",
    "chosen_idx, mask_pred, result, init_mask, dices = evolution(\n",
    "    masks=masks,\n",
    "    caches=cache_volume,\n",
    "    idx=idx,\n",
    "    target_idx=1,\n",
    "    start_radius=4,\n",
    "    n_round=10,\n",
    "    gaussian_config={\n",
    "        'sigma': 10.0,\n",
    "        'prev_sigma': 3.5,\n",
    "    },\n",
    "    seed=(time_ns() & (2**32 - 1)),\n",
    "    # seed=10,\n",
    ")\n",
    "\n",
    "target_mask = masks[idx].copy() == 1\n",
    "img = volumes[idx]\n",
    "\n",
    "f, axes = plt.subplots(2, 2)\n",
    "axes[0, 0].imshow(mask_pred[0, chosen_idx])\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[1, 0].imshow(init_mask*10 + target_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "\n",
    "axes[0, 0].set_title('Pred')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Target with init overlay')\n",
    "axes[1, 1].set_title('Image')\n",
    "\n",
    "print(dices)\n",
    "\n",
    "f, axes = plt.subplots(3, 4)\n",
    "for i1 in range(3):\n",
    "    for i2 in range(4):\n",
    "        if i1 * 4 + i2 >= len(result): break\n",
    "        axes[i1, i2].imshow(result[i1 * 4 + i2])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "def expansion_metric(a1: Tensor, a2: Tensor):\n",
    "    if not isinstance(a1, Tensor):\n",
    "        a1 = Tensor(a1)\n",
    "    if not isinstance(a2, Tensor):\n",
    "        a2 = Tensor(a2)\n",
    "    intersection = (a1 * a2).sum()\n",
    "    # Check the intersection coverage compare to the max\n",
    "    expansion_ratio = torch.max(a1.sum(), a2.sum()) / intersection\n",
    "    coverage_ratio = intersection / torch.min(a1.sum(), a2.sum())\n",
    "    return expansion_ratio, coverage_ratio\n",
    "\n",
    "expansion_ratio, coverage_ratio = expansion_metric(result[0] > 0.0, result[-1] > 0.0)\n",
    "print(\n",
    "    expansion_ratio,\n",
    "    coverage_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkern(l=5, sig=1.):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length `l` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sig))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def create_gaussian_2d_kernel(length: int, sigma: float):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length `l` and a sigma of `sig`\n",
    "    \"\"\"\n",
    "    ax = torch.linspace(-(length - 1) / 2.0, (length - 1) / 2.0, length)\n",
    "    gauss = torch.exp(-0.5 * torch.square(ax) / torch.square(torch.as_tensor(sigma)))\n",
    "    kernel = torch.outer(gauss, gauss)\n",
    "    return kernel / torch.sum(kernel)\n",
    "\n",
    "gkern() - create_gaussian_2d_kernel(5, 1.).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "import uuid\n",
    "from uuid import UUID\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeamSearchOptionData:\n",
    "    obj_id: UUID = field(default_factory=uuid.uuid4)\n",
    "    prev_id: Optional[UUID] = None\n",
    "    sigmoid_threshold: float = 0.0\n",
    "    score: float = 0.0\n",
    "    prev_score: float = 0.0\n",
    "    frame_idx : Optional[int] = None\n",
    "    next_frame_idx: Optional[int] = None\n",
    "    mask_logits: torch.Tensor = None\n",
    "    cyclic_count: int = 0\n",
    "\n",
    "    def get_mask(self) -> torch.Tensor:\n",
    "        if self.prev_id is None:\n",
    "            return self.mask_logits\n",
    "        \n",
    "        return torch.sigmoid(self.mask_logits) > self.sigmoid_threshold\n",
    "    \n",
    "@dataclass\n",
    "class BeamSearchTracing:\n",
    "    data: BeamSearchOptionData = None\n",
    "    children: List[BeamSearchOptionData] = field(default_factory=list)\n",
    "\n",
    "class Tracing:\n",
    "    def __init__(self) -> None:\n",
    "        self.trace_dict: Dict[str, BeamSearchTracing] = {}\n",
    "        pass\n",
    "\n",
    "    def add(self, obj: BeamSearchOptionData):\n",
    "        # Register itself into the system\n",
    "        self.trace_dict[obj.obj_id] = BeamSearchTracing(data=obj)\n",
    "        # Link the current object\n",
    "        prev_data = self.trace_dict.get(obj.prev_id, None)\n",
    "        if prev_data is None: return\n",
    "        prev_data.children.append(obj)\n",
    "        pass\n",
    "\n",
    "    def flatten(self):\n",
    "        result = []\n",
    "        for value in self.trace_dict.values():\n",
    "            result.extend(value.children)\n",
    "        return result\n",
    "    \n",
    "    def tracing(self, prev_id) -> List[BeamSearchOptionData]:\n",
    "        # Safe-guard the tracing\n",
    "        counter = 1000\n",
    "        prev = self.trace_dict[prev_id]\n",
    "        result = []\n",
    "        while prev.data.prev_id is not None and counter > 0:\n",
    "            result.append(prev.data)\n",
    "            prev = self.trace_dict[prev.data.prev_id]\n",
    "            counter = counter - 1\n",
    "            pass\n",
    "        return result\n",
    "\n",
    "def make_gauss_point_mask(x, y, shape=(512, 512), radius=3, gaussian_config=None):\n",
    "    result = np.zeros(shape)\n",
    "    xmax = min(x + radius, shape[0])\n",
    "    ymax = min(y + radius, shape[1])\n",
    "    xmin = max(x - radius, 0)\n",
    "    ymin = max(y - radius, 0)\n",
    "    result[ymin:ymax, xmin:xmax] = 1.0\n",
    "\n",
    "    if gaussian_config:\n",
    "        result = gaussian_filter(result, sigma=gaussian_config['sigma'])\n",
    "        result = (result - np.min(result)) / (np.max(result) - np.min(result))\n",
    "    \n",
    "    result = torch.as_tensor(result)\n",
    "    return result\n",
    "\n",
    "def make_centroid(input_masks, local_mean_centroid: np.ndarray, is_input_reversed=False):\n",
    "    # `is_input_reversed: bool`: it's proven that reversed input have more consistent feature.\n",
    "    # Therefore, our feature is compute on reversed input. If the input is not reversed,\n",
    "    # set `is_input_reversed=True` so it will be done for you\n",
    "\n",
    "    if not is_input_reversed:\n",
    "        masks = input_masks[::-1]\n",
    "    else:\n",
    "        masks = input_masks\n",
    "\n",
    "    starts, ends = get_all_organ_range(masks)\n",
    "    starts = np.nan_to_num(starts.astype(np.float32), nan=0.0)\n",
    "    ends = np.nan_to_num(ends.astype(np.float32), nan=0.0)\n",
    "    dur = ends - starts\n",
    "    dur: np.ndarray = np.pad(\n",
    "        np.reshape(dur, [-1, 1]), \n",
    "        pad_width=[(0, 0), (0, 2)], \n",
    "        constant_values=512\n",
    "    )\n",
    "    # Take the centroid in z-axis of local organ, and then add back the starts\n",
    "    proposal = dur * local_mean_centroid + np.pad(\n",
    "        np.reshape(starts, [-1, 1]), \n",
    "        pad_width=[(0, 0), (0, 2)], \n",
    "        constant_values=0.0\n",
    "    )\n",
    "\n",
    "    if not is_input_reversed:\n",
    "        # reverse the z-axis via subtraction\n",
    "        proposal[:, 0] = masks.shape[0] - proposal[:, 0]\n",
    "        pass\n",
    "    \n",
    "    return np.ceil(proposal).astype(np.uint16)\n",
    "\n",
    "class BeamSearchInferenceEngine:\n",
    "    LOCAL_MEAN_CENTROID = np.zeros((14, 3))\n",
    "    LOCAL_MEAN_CENTROID[1] = np.array([0.38626369, 0.54490201, 0.67218827])\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            volumes: Tensor, \n",
    "            caches: Tensor, \n",
    "            masks: Tensor,\n",
    "            stability_config: Dict[str, object],\n",
    "            gaussian_config: Dict[str, object],\n",
    "            start_radius: float,\n",
    "            seed: int = None,\n",
    "            strategy_name: str = '',\n",
    "            allow_evolution: bool = False,\n",
    "            ) -> None:\n",
    "        self.volumes = volumes\n",
    "        self.caches = caches\n",
    "        self.masks = masks\n",
    "        self.seed = seed or time_ns() % (2**32 - 1)\n",
    "        self.gaussian_config = gaussian_config\n",
    "        self.start_radius = start_radius\n",
    "        self.strategy_name = strategy_name\n",
    "        self.allow_evolution = allow_evolution\n",
    "        \n",
    "        self.stability_config = self.prepare_default_stability_config(stability_config)\n",
    "        self.starts, self.ends = get_all_organ_range(masks)\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def prepare_default_stability_config(self, stability_config: Dict[str, object]):\n",
    "        stability_config = stability_config or {}\n",
    "        stability_config['threshold_start'] = stability_config.get('threshold_start', 0.1)\n",
    "        stability_config['threshold_end'] = stability_config.get('threshold_end', 0.9)\n",
    "        stability_config['threshold_num'] = stability_config.get('threshold_num', 10)\n",
    "        stability_config['offset'] = stability_config.get('offset', 0.1)\n",
    "        return stability_config\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def core_inference(self, idx: int, previous_mask: Tensor):\n",
    "        original_size = self.caches[idx]['original_size']\n",
    "        input_size = self.caches[idx]['input_size']\n",
    "        img_emb = self.caches[idx]['img_emb']\n",
    "\n",
    "        _, _, _, mask_input_torch = sam_train.prepare_prompt(\n",
    "            original_size=original_size, mask_input=previous_mask[None, ...]\n",
    "            )\n",
    "\n",
    "        mask_logits, _, _ = sam_train.predict_torch(\n",
    "            image_emb=img_emb,  # 1, 256, 64, 64\n",
    "            input_size=input_size,\n",
    "            original_size=original_size,\n",
    "            multimask_output=True,\n",
    "            # Get the logits to compute the stability\n",
    "            return_logits=True,\n",
    "            mask_input=mask_input_torch,\n",
    "        )\n",
    "\n",
    "        mask_pred = mask_logits > 0.0\n",
    "        \n",
    "        chosen_idx, _ = pick_best_mask(\n",
    "            pred_multi_mask=mask_pred,\n",
    "            previous_mask=previous_mask,\n",
    "            gt_binary_mask=None,\n",
    "            device='cpu',\n",
    "            strategy='prev'\n",
    "        )\n",
    "        \n",
    "        return chosen_idx, mask_logits\n",
    "    \n",
    "    def confidence_score(self, mask_logits, threshold):\n",
    "        # Idea: confidence is high when the prob of \n",
    "        # foreground high and prob of background is low\n",
    "        sigmoid_mask = torch.sigmoid(mask_logits).numpy()\n",
    "\n",
    "        _mean = lambda x: np.nan_to_num(np.mean(x), 0.0)\n",
    "        foreground_score = _mean(\n",
    "            sigmoid_mask[sigmoid_mask >= threshold]\n",
    "            )\n",
    "        background_score = 1.0 - _mean(sigmoid_mask[sigmoid_mask < threshold])\n",
    "        return np.mean([foreground_score, background_score])\n",
    "    \n",
    "    def calculate_stability_score_with_sigmoid(\n",
    "        self, masks: torch.Tensor, mask_threshold: float, threshold_offset: float\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Exactly like the `calculate_stability_score`, but using sigmoid for better scale\n",
    "        \"\"\"\n",
    "        sigmoid_masks = torch.sigmoid(masks)\n",
    "        intersections = (\n",
    "            (sigmoid_masks > (mask_threshold + threshold_offset))\n",
    "            .sum(-1, dtype=torch.int16)\n",
    "            .sum(-1, dtype=torch.int32)\n",
    "        )\n",
    "        unions = (\n",
    "            (sigmoid_masks > (mask_threshold - threshold_offset))\n",
    "            .sum(-1, dtype=torch.int16)\n",
    "            .sum(-1, dtype=torch.int32)\n",
    "        )\n",
    "        return intersections / unions\n",
    "    \n",
    "    def generate_option(self, option: BeamSearchOptionData, is_forward=True) -> List[BeamSearchOptionData]:\n",
    "        previous_mask = option.get_mask()\n",
    "        chosen_idx, mask_logits = self.core_inference(\n",
    "            idx=option.next_frame_idx, previous_mask=previous_mask\n",
    "        )\n",
    "        \n",
    "        options = self.generate_next(\n",
    "            current_chosen_mask_logits=mask_logits[0, chosen_idx], \n",
    "            prev_option=option,\n",
    "            is_forward=is_forward\n",
    "        )\n",
    "\n",
    "        evolution_option = self.evolution_generate(current_chosen_mask_logits=mask_logits[0, chosen_idx], prev_option=option)\n",
    "        return options + evolution_option\n",
    "    \n",
    "    def evolution_generate(self, \n",
    "            current_chosen_mask_logits: torch.Tensor, \n",
    "            prev_option: BeamSearchOptionData,\n",
    "        ) -> List[BeamSearchOptionData]:\n",
    "        if not self.allow_evolution:\n",
    "            return []\n",
    "        if prev_option.frame_idx is None:\n",
    "            return []\n",
    "        if prev_option.cyclic_count > 3:\n",
    "            print(\"Exceed cyclic count...\")\n",
    "            return []\n",
    "\n",
    "        # Evolution consider cyclic inference on itself, therefore\n",
    "        # consider the previous score (not include the current score)\n",
    "        prev_score = prev_option.prev_score\n",
    "        previous_mask = torch.sigmoid(current_chosen_mask_logits) > 0.5\n",
    "        chosen_idx, mask_logits = self.core_inference(\n",
    "            idx=prev_option.frame_idx, previous_mask=previous_mask\n",
    "        )\n",
    "        score = self.confidence_score(\n",
    "            mask_logits=mask_logits[0, chosen_idx],\n",
    "            threshold=0.5,\n",
    "        )\n",
    "        score = prev_score + np.log(score + 1e-30)\n",
    "        if score < prev_option.score:\n",
    "            return []\n",
    "        \n",
    "        return [\n",
    "            BeamSearchOptionData(\n",
    "                # Skip object\n",
    "                prev_id=prev_option.prev_id,\n",
    "                sigmoid_threshold=0.5,\n",
    "                score=score,\n",
    "                prev_score=prev_score,\n",
    "                frame_idx=prev_option.frame_idx,\n",
    "                next_frame_idx=prev_option.next_frame_idx,\n",
    "                mask_logits=mask_logits[0, chosen_idx],\n",
    "                cyclic_count=prev_option.cyclic_count + 1\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def generate_next(\n",
    "            self, \n",
    "            current_chosen_mask_logits: torch.Tensor, \n",
    "            prev_option: BeamSearchOptionData,\n",
    "            is_forward=True,\n",
    "        ) -> List[BeamSearchOptionData]:\n",
    "        \n",
    "        options : List[BeamSearchOptionData] = []\n",
    "        prev_score = prev_option.score\n",
    "        idx = prev_option.next_frame_idx\n",
    "        next_frame_idx = idx + 1 if is_forward else idx - 1\n",
    "        start = self.stability_config['threshold_start']\n",
    "        end = self.stability_config['threshold_end']\n",
    "        num = self.stability_config['threshold_num']\n",
    "        for value in np.linspace(start=start, stop=end, num=num):\n",
    "            # score = self.calculate_stability_score_with_sigmoid(\n",
    "            #     masks=current_chosen_mask_logits,\n",
    "            #     mask_threshold=value,\n",
    "            #     threshold_offset=self.stability_config['offset']\n",
    "            #     )\n",
    "            score = self.confidence_score(\n",
    "                mask_logits=current_chosen_mask_logits,\n",
    "                threshold=value,\n",
    "            )\n",
    "            score = prev_score + np.log(score + 1e-30)\n",
    "            new_option = BeamSearchOptionData(\n",
    "                sigmoid_threshold=value,\n",
    "                prev_id=prev_option.obj_id,\n",
    "                mask_logits=current_chosen_mask_logits,\n",
    "                score=score,\n",
    "                prev_score=prev_score,\n",
    "                frame_idx=idx,\n",
    "                next_frame_idx=next_frame_idx\n",
    "            )\n",
    "            options.append(new_option)\n",
    "        return options\n",
    "\n",
    "    def ranking_fn(self, options: List[BeamSearchOptionData]):\n",
    "        if len(options) == 0: return []\n",
    "        return sorted(options, key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    def seeding_strategies(self, target_idx: int, **kwargs):\n",
    "        start_idx = kwargs['start_idx']\n",
    "        end_idx = kwargs['end_idx']\n",
    "        if self.strategy_name == 'random-pick-one':\n",
    "            init_mask = torch.as_tensor(self.masks[start_idx - 1].copy() == target_idx)\n",
    "            init_mask = pick_one_pixel(\n",
    "                init_mask, \n",
    "                radius=self.start_radius,\n",
    "                gaussian_config=self.gaussian_config,\n",
    "                seed=self.seed\n",
    "            )\n",
    "            return init_mask, start_idx\n",
    "        \n",
    "        if self.strategy_name == 'local-mean-centroid':\n",
    "            assert target_idx == 1, f\"Only support target-idx == 1, given {target_idx}\"\n",
    "            proposal = make_centroid(masks, self.LOCAL_MEAN_CENTROID)\n",
    "            z, y, x = proposal[1].tolist()\n",
    "            assert z > start_idx and z < end_idx, f\"Proposal {z=} is out of wanted range: ({start_idx}, {end_idx})\"\n",
    "            # Prepare the mask\n",
    "            init_mask = make_gauss_point_mask(\n",
    "                x=x, y=y, \n",
    "                radius=self.start_radius,\n",
    "                gaussian_config=self.gaussian_config,\n",
    "            )\n",
    "            return init_mask, z\n",
    "        \n",
    "        init_mask = torch.as_tensor(self.masks[start_idx - 1].copy() == target_idx)\n",
    "        return init_mask, start_idx\n",
    "    \n",
    "    def beam_search_inference(\n",
    "            self, \n",
    "            start_idx: int, \n",
    "            end_idx: int,\n",
    "            target_idx: int, \n",
    "            beam_width: int = 3,\n",
    "        ):\n",
    "\n",
    "        init_mask, proposal_start_idx = self.seeding_strategies(\n",
    "            target_idx=target_idx, \n",
    "            start_idx=start_idx,\n",
    "            end_idx=end_idx,\n",
    "        )\n",
    "        \n",
    "        forward_data = self.beam_search(start_idx, end_idx, beam_width, init_mask, proposal_start_idx, is_forward=True)\n",
    "        init_mask = forward_data[0]\n",
    "        backward_data = self.beam_search(start_idx, end_idx, beam_width, init_mask, proposal_start_idx, is_forward=False)\n",
    "        \n",
    "        return forward_data, backward_data, init_mask, proposal_start_idx\n",
    "\n",
    "    def beam_search(self, start_idx, end_idx, beam_width, init_mask, proposal_start_idx, is_forward=True):\n",
    "        if is_forward:\n",
    "            filter_for_tracing = lambda opt: opt.next_frame_idx <= end_idx + 1\n",
    "            filter_next_round  = lambda opt: opt.next_frame_idx <= end_idx\n",
    "            filter_done = lambda opt: opt.next_frame_idx == end_idx + 1\n",
    "        else:\n",
    "            filter_for_tracing = lambda opt: opt.next_frame_idx >= start_idx - 1\n",
    "            filter_next_round  = lambda opt: opt.next_frame_idx >= start_idx\n",
    "            filter_done = lambda opt: opt.next_frame_idx == start_idx - 1\n",
    "        \n",
    "        options: List[BeamSearchOptionData] = [\n",
    "            BeamSearchOptionData(\n",
    "                mask_logits=init_mask, \n",
    "                frame_idx=None, \n",
    "                next_frame_idx=proposal_start_idx if is_forward else proposal_start_idx - 1\n",
    "                )\n",
    "            ]\n",
    "        tracing_tool = Tracing()\n",
    "        tracing_tool.add(options[0])\n",
    "        while len(options) > 0:\n",
    "            buffer = []\n",
    "            for option in options:\n",
    "                new_options = self.generate_option(option, is_forward=is_forward)\n",
    "                buffer.extend(new_options)\n",
    "                pass\n",
    "\n",
    "            options = self.ranking_fn(buffer)[:beam_width]\n",
    "            if len(options): \n",
    "                options = list(filter(filter_for_tracing, options))\n",
    "                # For tracing\n",
    "                for option in options:\n",
    "                    tracing_tool.add(option)\n",
    "            if len(options):\n",
    "                # Limit-again\n",
    "                options = list(filter(filter_next_round, options))\n",
    "            pass\n",
    "\n",
    "        # Tracing forward\n",
    "        done_option = filter(filter_done, tracing_tool.flatten())\n",
    "        best_option: BeamSearchOptionData = max(done_option, key=lambda x:x.score)\n",
    "        data = [best_option.get_mask()]\n",
    "        opts = []\n",
    "        opts.extend([opt for opt in tracing_tool.tracing(prev_id=best_option.prev_id)])\n",
    "        print(list(map(lambda x: x.frame_idx, opts)))\n",
    "        data.extend([x.get_mask() for x in opts])\n",
    "\n",
    "        return data[::-1]\n",
    "    \n",
    "\n",
    "volumes, masks = preprocessor.run_with_config(\n",
    "    image_file=IMAGE_PATH,\n",
    "    gt_file=MASK_PATH,\n",
    "    config_name=IMAGE_TYPE.ABDOMEN_SOFT_TISSUES_ABDOMEN_LIVER,\n",
    ")\n",
    "engine = BeamSearchInferenceEngine(\n",
    "    volumes=volumes, \n",
    "    caches=cache_volume, \n",
    "    masks=masks,\n",
    "    # stability_config={\n",
    "    #     'threshold_start': 0.3,\n",
    "    #     'threshold_end': 0.7\n",
    "    # },\n",
    "    stability_config=None,\n",
    "    start_radius=10,\n",
    "    gaussian_config={'sigma': 10.0},\n",
    "    strategy_name='local-mean-centroid',\n",
    "    allow_evolution=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx=100\n",
    "end_idx=start_idx + 70\n",
    "forward_data, backward_data, init_mask, proposal_start_idx = engine.beam_search_inference(\n",
    "    start_idx=start_idx,\n",
    "    end_idx=end_idx,\n",
    "    target_idx=1,\n",
    "    beam_width=3,\n",
    ")\n",
    "print(proposal_start_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.stack([*backward_data[::-1], *forward_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = start_idx + 4\n",
    "target_mask = masks[idx].copy() == 1\n",
    "img = volumes[idx]\n",
    "f, axes = plt.subplots(2, 2)\n",
    "# plt.imshow(Image1, cmap='gray')\n",
    "target_mask = np.stack([target_mask, target_mask, target_mask]).transpose([1, 2, 0]).astype(np.uint16) * 255\n",
    "axes[0, 0].imshow(target_mask, interpolation=None)\n",
    "axes[0, 0].imshow(data[idx - start_idx], cmap='jet', interpolation=None, alpha=0.5)\n",
    "\n",
    "axes[0, 1].imshow(target_mask)\n",
    "axes[1, 0].imshow(init_mask)\n",
    "axes[1, 1].imshow(img)\n",
    "\n",
    "axes[0, 0].set_title(f'Pred {idx}')\n",
    "axes[0, 1].set_title('Target')\n",
    "axes[1, 0].set_title('Init mask')\n",
    "axes[1, 1].set_title('Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_imshow(data: np.ndarray, start_idx: int):\n",
    "    l = data.shape[0]\n",
    "    n_row = int(np.sqrt(l))\n",
    "    n_col = int(np.ceil(l // n_row))\n",
    "    f, axes = plt.subplots(n_row, n_col, figsize=(15, 15), squeeze=False)\n",
    "    for row in range(n_row):\n",
    "        for col in range(n_col):\n",
    "            idx = row * n_col + col\n",
    "            if idx >= l: break\n",
    "            target_mask = masks[idx + start_idx].copy() == 1\n",
    "            # img = volumes[idx]\n",
    "            target_mask = np.stack(\n",
    "                [target_mask, target_mask, target_mask]).transpose([1, 2, 0]).astype(np.uint16) * 255\n",
    "            axes[row, col].imshow(target_mask, interpolation=None)\n",
    "            axes[row, col].imshow(data[idx], cmap='jet', interpolation=None, alpha=0.5)\n",
    "            axes[row, col].axis('off')\n",
    "            \n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "grid_imshow(data, start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "gt_files = sorted(list(glob(f\"{VAL_ROOT}/labels/*nii.gz\")))\n",
    "image_files = sorted(list(glob(f\"{VAL_ROOT}/images/*nii.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only care about the liver\n",
    "local_mean_centroid = np.zeros((14, 3))\n",
    "local_mean_centroid[1] = np.array([0.38626369, 0.54490201, 0.67218827])\n",
    "\n",
    "def make_centroid(masks, local_mean_centroid: np.ndarray):\n",
    "    # NOTE: Remember to reverse the masks\n",
    "    starts, ends = get_all_organ_range(masks)\n",
    "    starts = np.nan_to_num(starts.astype(np.float32), nan=0.0)\n",
    "    ends = np.nan_to_num(ends.astype(np.float32), nan=0.0)\n",
    "    dur = ends - starts\n",
    "    dur: np.ndarray = np.pad(\n",
    "        np.reshape(dur, [-1, 1]), \n",
    "        pad_width=[(0, 0), (0, 2)], \n",
    "        constant_values=512\n",
    "    )\n",
    "    # Take the centroid in z-axis of local organ, and then add back the starts\n",
    "    proposal = dur * local_mean_centroid + np.pad(\n",
    "        np.reshape(starts, [-1, 1]), \n",
    "        pad_width=[(0, 0), (0, 2)], \n",
    "        constant_values=0.0\n",
    "    )\n",
    "    \n",
    "    return np.ceil(proposal).astype(np.uint16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 7\n",
    "volumes, masks = preprocessor.run_with_config(\n",
    "    image_file=image_files[file_idx],\n",
    "    gt_file=gt_files[file_idx],\n",
    "    config_name=IMAGE_TYPE.ABDOMEN_SOFT_TISSUES_ABDOMEN_LIVER,\n",
    ")\n",
    "volumes, masks = volumes[::-1], masks[::-1]\n",
    "proposal = make_centroid(masks, local_mean_centroid)\n",
    "z, y, x = proposal[1].tolist()\n",
    "\n",
    "plt.imshow(masks[z] == 1.0)\n",
    "plt.plot(x, y, markersize=10, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ins = []\n",
    "for file_idx in range(0, 20):\n",
    "    volumes, masks = preprocessor.run_with_config(\n",
    "        image_file=image_files[file_idx],\n",
    "        gt_file=gt_files[file_idx],\n",
    "        config_name=IMAGE_TYPE.ABDOMEN_SOFT_TISSUES_ABDOMEN_LIVER,\n",
    "    )\n",
    "    volumes, masks = volumes[::-1], masks[::-1]\n",
    "    z, y, x = volumes.shape\n",
    "    x_mean_per, y_mean_per, z_mean_per = (0.6721882690535713, 0.5449020087665863, 0.352355387374095)\n",
    "    x = int(x * x_mean_per)\n",
    "    y = int(y * y_mean_per)\n",
    "    z = int(z * z_mean_per)\n",
    "    is_in = masks[z, y, x]\n",
    "    is_ins.append(is_in)\n",
    "    # plt.imshow(masks[z] == 1.0)\n",
    "    # plt.plot(x, y, markersize=10, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for file_idx in range(0, 20):\n",
    "file_idx = 7\n",
    "volumes, masks = preprocessor.run_with_config(\n",
    "    image_file=image_files[file_idx],\n",
    "    gt_file=gt_files[file_idx],\n",
    "    config_name=IMAGE_TYPE.ABDOMEN_SOFT_TISSUES_ABDOMEN_LIVER,\n",
    ")\n",
    "volumes, masks = volumes[::-1], masks[::-1]\n",
    "z, y, x = volumes.shape\n",
    "x_mean_per, y_mean_per, z_mean_per = (0.6721882690535713, 0.5449020087665863, 0.352355387374095)\n",
    "x = int(x * x_mean_per)\n",
    "y = int(y * y_mean_per)\n",
    "z = int(z * z_mean_per)\n",
    "plt.imshow(masks[z])\n",
    "plt.plot(x, y, markersize=10, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_score(logits, threshold):\n",
    "    # Idea: confidence is high when the prob of \n",
    "    # foreground high and prob of background is low\n",
    "    foreground_score = np.mean(logits[logits >= threshold])\n",
    "    background_score = 1.0 - np.mean(logits[logits < threshold])\n",
    "    return np.mean([foreground_score, background_score])\n",
    "\n",
    "sigmoid_mask = tracing_tool[0][-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(tracing_tool[0], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(tracing_tool[0], key=lambda x: x[1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_masks = torch.sigmoid(sigmoid_mask)\n",
    "mask_threshold = 0.5\n",
    "threshold_offset = 0.1\n",
    "intersections = (\n",
    "            (sigmoid_masks > (mask_threshold + threshold_offset))\n",
    "            .sum(-1, dtype=torch.int16)\n",
    "            .sum(-1, dtype=torch.int32)\n",
    "        )\n",
    "\n",
    "unions = (\n",
    "            (sigmoid_masks > (mask_threshold - threshold_offset))\n",
    "            .sum(-1, dtype=torch.int16)\n",
    "            .sum(-1, dtype=torch.int32)\n",
    "        )\n",
    "print(intersections, unions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_score(logits=torch.sigmoid(sigmoid_mask).numpy(), threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fbrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
